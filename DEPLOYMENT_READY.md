# ğŸš€ BetterGut AI Pipeline - Ready for RTX 3090 Deployment

## ğŸ“ Clean File Structure (After Cleanup)

**Core Files (All Needed):**
```
ai-pipeline/
â”œâ”€â”€ ğŸ“„ api.py                          # FastAPI service
â”œâ”€â”€ ğŸ“„ crawl_health_data.py           # Main crawler script  
â”œâ”€â”€ ğŸ“„ requirements.txt               # Python dependencies
â”œâ”€â”€ ğŸ“„ Dockerfile.production          # Optimized for GPU servers
â”œâ”€â”€ ğŸ“„ README.md                      # Documentation
â””â”€â”€ ğŸ“„ .env.example                   # Environment template

ğŸ“‚ crawlers/                          # Data collection modules
â”œâ”€â”€ ğŸ“„ health_crawler.py              # Main orchestrator
â”œâ”€â”€ ğŸ“„ pubmed_crawler.py              # Scientific articles (PubMed)
â”œâ”€â”€ ğŸ“„ institution_crawler.py         # Government sources (NIH, CDC)
â””â”€â”€ ğŸ“„ specialist_crawler.py          # Health specialist websites

ğŸ“‚ models/                            # AI model implementations
â”œâ”€â”€ ğŸ“„ llama3_service.py              # Llama 3 integration
â””â”€â”€ ğŸ“„ quantized_models.py            # RTX 3090 optimized models

ğŸ“‚ rag/                               # Retrieval-Augmented Generation
â””â”€â”€ ğŸ“„ rag_system.py                  # Vector database & embeddings

ğŸ“‚ config/                            # Configuration management
â””â”€â”€ ğŸ“„ storage_config.py              # Centralized storage paths

ğŸ“‚ storage/                           # Organized data storage
â”œâ”€â”€ ğŸ“‚ crawled_data/                  # Raw collected data
â”‚   â”œâ”€â”€ ğŸ“‚ pubmed/                    # Scientific articles
â”‚   â”œâ”€â”€ ğŸ“‚ institutions/              # Government content
â”‚   â””â”€â”€ ğŸ“‚ specialists/               # Expert content
â”œâ”€â”€ ğŸ“‚ rag_database/                  # RAG system data
â”‚   â”œâ”€â”€ ğŸ“‚ chroma_db/                 # Vector database
â”‚   â””â”€â”€ ğŸ“‚ embeddings_cache/          # Cached embeddings
â”œâ”€â”€ ğŸ“‚ models/                        # AI models cache
â”‚   â”œâ”€â”€ ğŸ“‚ quantized/                 # RTX 3090 models
â”‚   â””â”€â”€ ğŸ“‚ embeddings/                # Embedding models
â”œâ”€â”€ ğŸ“‚ logs/                          # Application logs
â””â”€â”€ ğŸ“‚ temp/                          # Temporary files

ğŸ“‚ test scripts/ (Development only)
â”œâ”€â”€ ğŸ“„ test_setup.py                  # Complete test suite
â”œâ”€â”€ ğŸ“„ test_manual.py                 # Manual testing
â””â”€â”€ ğŸ“„ docker_test_simulation.sh      # Docker simulation
```

## ğŸ—‘ï¸ Files Removed for Clean Structure

- âŒ `data/` directory (replaced by organized `storage/`)
- âŒ `analyze_files.py` (cleanup script, no longer needed)

## ğŸ³ Docker Deployment Commands

### Method 1: Docker Compose (Recommended)
```bash
# Navigate to project root
cd /path/to/bettergut

# Deploy with GPU support
docker-compose -f docker-compose.ai.yml up --build

# Check container status
docker-compose -f docker-compose.ai.yml ps

# View logs
docker-compose -f docker-compose.ai.yml logs -f bettergut-ai
```

### Method 2: Manual Docker Build
```bash
# Build the image
docker build -f ai-pipeline/Dockerfile.production -t bettergut-ai ai-pipeline/

# Run with GPU support
docker run --gpus all \
  -p 8001:8001 \
  -v $(pwd)/ai-pipeline/storage:/app/storage \
  -e CUDA_VISIBLE_DEVICES=0 \
  -e MAX_CRAWL_ARTICLES=50 \
  --name bettergut-ai \
  bettergut-ai
```

### Method 3: One-Command Deployment Script
```bash
# Run the automated deployment script
sudo bash scripts/deploy_gpu_server.sh
```

## ğŸ§ª Testing the Crawlers

### Test Crawler Functionality
```bash
# Test with small dataset
docker exec bettergut-ai python crawl_health_data.py --crawl-only --max-articles 10

# Test with more comprehensive dataset
docker exec bettergut-ai python crawl_health_data.py --crawl-only --max-articles 50

# Full pipeline (crawl + build RAG database)
docker exec bettergut-ai python crawl_health_data.py --max-articles 50
```

### Monitor GPU Usage
```bash
# Check GPU utilization
nvidia-smi -l 1

# Check container GPU access
docker exec bettergut-ai nvidia-smi

# Monitor memory usage
docker exec bettergut-ai python -c "import torch; print(f'GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB')"
```

## ğŸ“Š Expected Crawler Output

### Data Collection Sources:
1. **PubMed** (Scientific Literature)
   - Recent gut health research papers
   - Abstracts and metadata
   - Saved as: `storage/crawled_data/pubmed/pubmed_articles_YYYYMMDD_HHMMSS.json`

2. **Health Institutions** (Government Sources)  
   - NIH, CDC, Harvard Nutrition guidelines
   - Evidence-based health information
   - Saved as: `storage/crawled_data/institutions/institutions_articles_YYYYMMDD_HHMMSS.json`

3. **Specialist Websites** (Expert Content)
   - Gastroenterologist recommendations
   - Nutrition specialist advice
   - Saved as: `storage/crawled_data/specialists/specialists_articles_YYYYMMDD_HHMMSS.json`

### Data Format Example:
```json
{
  "title": "Gut Microbiome and Digestive Health",
  "content": "Scientific content...",
  "source": "PubMed",
  "url": "https://pubmed.ncbi.nlm.nih.gov/...",
  "topics": ["gut health", "microbiome"],
  "crawl_timestamp": "2025-08-03T13:45:00Z"
}
```

## ğŸ”§ RTX 3090 Optimizations

### Quantized Models Available:
- **Llama 3 8B (4-bit)**: ~6GB VRAM, excellent quality
- **Mistral 7B (4-bit)**: ~5GB VRAM, fast inference  
- **CodeLlama 7B (4-bit)**: ~5GB VRAM, structured outputs

### GPU Configuration:
```yaml
environment:
  - CUDA_VISIBLE_DEVICES=0
  - GPU_MEMORY_FRACTION=0.8
  - QUANTIZED_MODEL_PATH=/app/storage/models/quantized
```

## ğŸ” Health Check & Monitoring

### API Endpoints:
- **Health Check**: `http://localhost:8001/health`
- **API Docs**: `http://localhost:8001/docs`
- **Start Crawling**: `POST http://localhost:8001/crawl/start`

### Storage Monitoring:
```bash
# Check storage usage
docker exec bettergut-ai du -h /app/storage

# Count crawled articles
docker exec bettergut-ai find /app/storage/crawled_data -name "*.json" | wc -l

# View latest crawl results
docker exec bettergut-ai ls -la /app/storage/crawled_data/pubmed/
```

## âœ… Deployment Readiness Checklist

- âœ… Clean file structure (no unused files)
- âœ… Docker configuration with GPU support
- âœ… Storage organization system
- âœ… RTX 3090 optimized models
- âœ… Automated deployment script
- âœ… Comprehensive testing suite
- âœ… Health monitoring endpoints
- âœ… Documentation and examples

## ğŸ¯ Next Steps

1. **Copy project to RTX 3090 server**
2. **Run deployment**: `sudo bash scripts/deploy_gpu_server.sh`
3. **Test crawlers**: `docker exec bettergut-ai python crawl_health_data.py --crawl-only --max-articles 10`
4. **Monitor GPU usage**: `nvidia-smi`
5. **Scale up**: Increase `--max-articles` as needed
6. **Integrate with your app**: Use API endpoints for health insights

---

**ğŸš€ Your BetterGut AI Pipeline is ready for production deployment on RTX 3090!**
